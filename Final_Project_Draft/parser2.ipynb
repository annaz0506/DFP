{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df737a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "import time\n",
    "import random\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from threading import Lock\n",
    "import csv\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1fda76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(job_title, city, state, page = 0):\n",
    "    # Generate Indeed search URL with optional page number\n",
    "    template = \"https://www.indeed.com/jobs?q={}&l={}\"\n",
    "    if page > 0:\n",
    "        template += \"start={}\".format(page*10) # Indeed uses 10 -> 2nd page, 20 -> 3rd page.\n",
    "    job_title = job_title.strip().replace(\" \", \"+\")\n",
    "    city = city.strip().replace(\" \", \"+\")\n",
    "    state = state.strip().replace(\" \", \"+\")\n",
    "    city_state = city + \"+\" + state\n",
    "    url = template.format(job_title, city_state)\n",
    "    return url        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d74c9bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only one thread prints at a time\n",
    "print_lock = Lock()\n",
    "\n",
    "def safe_print(message):\n",
    "    # Thread-safe print\n",
    "    with print_lock:\n",
    "        print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ceaacbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and configure a new webdriver instance\n",
    "def create_driver():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--start-maximized\") # Launches chrome in maximized window mode, so we don't have to resize\n",
    "    # Anti-detection\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\") # Tells chrome not to reveal it's controlled by automation\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"]) # Removes AutomationControlled flag\n",
    "    options.add_experimental_option('useAutomationExtension', False) # Stop default automation from Selenium\n",
    "    # Optional: turned off only if you would like see all windows\n",
    "    options.add_argument(\"--headless\")\n",
    "    \n",
    "    driver = webdriver.Chrome(options = options)\n",
    "    \n",
    "    driver.execute_cdp_cmd('Network.setUserAgentOverride', {\n",
    "# The code below is from Chrome console by typing navigator.userAgent\n",
    "        \"userAgent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36\"\n",
    "    })\n",
    "    \n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7db31148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_basic_info(post):\n",
    "    try:\n",
    "        title = post.find_element(By.CSS_SELECTOR, \"h2.jobTitle\").text\n",
    "        company = post.find_element(By.CSS_SELECTOR, \"span[data-testid='company-name']\").text\n",
    "        location = post.find_element(By.CSS_SELECTOR, \"div[data-testid='text-location']\").text\n",
    "        job_url = post.find_element(By.CSS_SELECTOR, \"h2.jobTitle a\").get_attribute(\"href\")\n",
    "        \n",
    "        # Try to get salary\n",
    "        try:\n",
    "            salary = post.find_element(By.CSS_SELECTOR, \"h2.mosaic-provider-jobcards-5vqdjd\").text\n",
    "        except NoSuchElementException:\n",
    "            salary = \"\"\n",
    "        \n",
    "        return (title, company, location, salary, job_url)\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting basic info: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "235c5939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_description(job_url):\n",
    "    # Get job description by opening url from a fresh browser instance for anti-detection pupose\n",
    "    driver = create_driver()\n",
    "    \n",
    "    try:\n",
    "        driver.get(job_url)\n",
    "        time.sleep(random.randint(2, 4)) # Pauses between 2 and 4 sendons to simulate a human browsing behavior and also let the page load fully\n",
    "        \n",
    "        WebDriverWait(driver, 10).until( # Waits up to 10 secs for elements appeared\n",
    "            EC.presence_of_element_located((By.ID, \"jobDescriptionText\"))\n",
    "        )\n",
    "        job_description = driver.find_element(By.ID, \"jobDescriptionText\").text\n",
    "        \n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        job_description = \"None\"\n",
    "    except Exception as e:\n",
    "        safe_print(f\"Error getting job description: {e}\")\n",
    "        job_description = \"None\"\n",
    "    finally:\n",
    "        driver.quit()\n",
    "    \n",
    "    return job_description        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a697c16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_job_with_description(job_data, index, total):\n",
    "    title, company, location, salary, job_url = job_data\n",
    "    \n",
    "    safe_print(f\"[Thread] Processing job {index + 1}/{total}: {title} at {company}\")\n",
    "    \n",
    "    # Add slight random delay to stagger requests\n",
    "    time.sleep(random.uniform(0.5, 1.5))\n",
    "    \n",
    "    # Get job description with fresh browser for anti-detection\n",
    "    job_description = get_job_description(job_url)\n",
    "    \n",
    "    record = (title, company, location, salary, job_url, job_description)\n",
    "    safe_print(f\"[Thread] Completed job {index + 1}/{total}: {title}\")\n",
    "    \n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb9f23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter job title: machine learning engineer\n",
      "Enter city: Pittsburgh\n",
      "Enter state: PA\n",
      "Enter starting page (0 for first page, 1 for second page, etc.): Starting from page 1\n",
      "Enter number of pages to scrape (default 1): Will scrape 1 pages\n",
      "Enter number of parallel threads (default 3, 5 recommended, max 15 ): Using 15 parallel threads\n",
      "Search URL: https://www.indeed.com/jobs?q=machine+learning+engineer&l=Pittsburgh+PA\n",
      "\n",
      "Scraping page 1...\n",
      "Found 16 jobs on page 1\n",
      "Collecting basic info for job 1/16...\n",
      "Collecting basic info for job 2/16...\n",
      "Collecting basic info for job 3/16...\n",
      "Collecting basic info for job 4/16...\n",
      "Collecting basic info for job 5/16...\n",
      "Collecting basic info for job 6/16...\n",
      "Collecting basic info for job 7/16...\n",
      "Collecting basic info for job 8/16...\n",
      "Collecting basic info for job 9/16...\n",
      "Collecting basic info for job 10/16...\n",
      "Collecting basic info for job 11/16...\n",
      "Collecting basic info for job 12/16...\n",
      "Collecting basic info for job 13/16...\n",
      "Collecting basic info for job 14/16...\n",
      "Collecting basic info for job 15/16...\n",
      "Collecting basic info for job 16/16...\n",
      "Collected 16 job listings from page 1\n",
      "Closed listing page browser to avoid detection\n",
      "\n",
      "Fetching job descriptions using 15 parallel threads...\n",
      "[Thread] Processing job 1/16: Software Engineer - Machine Learning at Hike2\n",
      "[Thread] Processing job 2/16: MACHINE LEARNING ENGINEER at Qeexo, Co.\n",
      "[Thread] Processing job 3/16: Machine Learning Engineer at Adidev Technologies Inc\n",
      "[Thread] Processing job 4/16: Data Scientist, New Graduate at Duolingo\n",
      "[Thread] Processing job 5/16: Principal Machine Learning Integration Engineer at Motional\n",
      "[Thread] Processing job 6/16: Data Engineer at PNC Financial Services Group\n",
      "[Thread] Processing job 7/16: Machine Learning Engineer at Govini\n",
      "[Thread] Processing job 8/16: DATA / AI ENGINEER at ZAP Solutions\n",
      "[Thread] Processing job 9/16: Quantitative Trading Analyst at SESCO Enterprises\n",
      "[Thread] Processing job 10/16: AI Research Engineer, New PhD Graduate at Duolingo\n",
      "[Thread] Processing job 11/16:  at \n",
      "[Thread] Processing job 12/16: Software Engineer, Planner Vehicle Dynamics at Waymo\n",
      "[Thread] Processing job 13/16: Artificial Intelligence(AI) Agent Developer at Visvero, Inc.\n",
      "[Thread] Processing job 14/16: Principal Machine Learning Engineer- Perception at Motional\n",
      "[Thread] Processing job 15/16: Staff Scientist, Data Sciences at Thermo Fisher Scientific\n",
      "[Thread] Completed job 10/16: AI Research Engineer, New PhD Graduate\n",
      "[Thread] Processing job 16/16: Research Scientist at Oculus\n",
      "[Thread] Completed job 5/16: Principal Machine Learning Integration Engineer\n",
      "[Thread] Completed job 7/16: Machine Learning Engineer\n",
      "[Thread] Completed job 13/16: Artificial Intelligence(AI) Agent Developer\n",
      "[Thread] Completed job 14/16: Principal Machine Learning Engineer- Perception\n",
      "[Thread] Completed job 12/16: Software Engineer, Planner Vehicle Dynamics\n",
      "[Thread] Completed job 15/16: Staff Scientist, Data Sciences\n",
      "[Thread] Completed job 1/16: Software Engineer - Machine Learning\n",
      "[Thread] Completed job 4/16: Data Scientist, New Graduate\n",
      "[Thread] Completed job 9/16: Quantitative Trading Analyst\n",
      "[Thread] Completed job 3/16: Machine Learning Engineer\n",
      "[Thread] Completed job 6/16: Data Engineer\n",
      "[Thread] Completed job 8/16: DATA / AI ENGINEER\n",
      "[Thread] Completed job 2/16: MACHINE LEARNING ENGINEER\n",
      "[Thread] Completed job 16/16: Research Scientist\n",
      "[Thread] Completed job 11/16: \n",
      "\n",
      "Completed 16 jobs in 16.87 seconds\n",
      "Average time per job: 1.05 seconds\n",
      "Completed page 1. Total jobs collected: 16\n",
      "\n",
      "================================================================================\n",
      "SCRAPING COMPLETE - Collected 16 jobs\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Job 1:\n",
      "Title: AI Research Engineer, New PhD Graduate\n",
      "Company: Duolingo\n",
      "Location: Pittsburgh, PA\n",
      "Salary: $131,800 - $186,000\n",
      "URL: https://www.indeed.com/rc/clk?jk=1e5d0983e18599b2&bb=10-r0rBpzhMBnWYIxB1ZJbohCBPq9Pf3c07xcyr43rYUxt-jXtm0zN56_KnkARXJWnLUp3p4b-QARmlRJinMQYzZZN09jUEgT0GA0D8l6BecTB4OR8Tvdkt-fJvkvFXhgjNgC4T58veuq6B8N7_kZH4M_X2muqvB&xkcb=SoDU67M3sVnfBoyEjh0CbzkdCdPP&fccid=1d7146bd38091a7a&vjs=3\n",
      "Description: Our mission at Duolingo is to develop the best education in the world and make it universally available. But we've got more left to do — and that's where you come in!\n",
      "Duolingo is the world's most popu...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Job 2:\n",
      "Title: Principal Machine Learning Integration Engineer\n",
      "Company: Motional\n",
      "Location: Remote in Pittsburgh, PA\n",
      "Salary: $168,000 - $283,900\n",
      "URL: https://www.indeed.com/rc/clk?jk=3844d8a48de00938&bb=10-r0rBpzhMBnWYIxB1ZJTeFVPityShHO8Ul3XPY5s-1CTzzUHM_weRwQkaa8tNTTp2Hpb8j1luZFpCgNc0qWfUB0l5gLmmGzDmMxuXlAiywoc2nWTQ7lc6bYrLhrU7SoNVnGQxK6JJwm1WOasQF0bot2ZaCAWVN&xkcb=SoAU67M3sVnfBoyEjh0PbzkdCdPP&fccid=86e1d3bf79028267&vjs=3\n",
      "Description: We are seeking a passionate and experienced engineer to help bring machine learning–based motion planning to the car. In this role, you will focus on deploying, optimizing, and maintaining ML-driven p...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Job 3:\n",
      "Title: Machine Learning Engineer\n",
      "Company: Govini\n",
      "Location: Pittsburgh, PA 15201 \n",
      "(Lower Lawrenceville area)\n",
      "Salary: \n",
      "URL: https://www.indeed.com/rc/clk?jk=c1fbba7eab24f4e7&bb=10-r0rBpzhMBnWYIxB1ZJQ1Yk13J_w6b2HHrARSkqlod2Cq13uhwuqotnM77cE_Qd-tBVQJ09MY3ymNvbGBW4hcfIwSLlqoA1pAsl8gZ6F8zFPG31D1KTUrfzzodDiZd47c_2KVTYgX63Lzl1esH_hkfatuEkUVs&xkcb=SoA967M3sVnfBoyEjh0NbzkdCdPP&fccid=932bcab1f7ee18f8&vjs=3\n",
      "Description: Company Description\n",
      "\n",
      "Govini transforms Defense Acquisition from an outdated manual process to a software-driven strategic advantage for the United States. Our flagship product, Ark, supports Supply Ch...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Job 4:\n",
      "Title: Artificial Intelligence(AI) Agent Developer\n",
      "Company: Visvero, Inc.\n",
      "Location: Pittsburgh, PA 15205\n",
      "Salary: \n",
      "URL: https://www.indeed.com/rc/clk?jk=7978d0d96d118382&bb=10-r0rBpzhMBnWYIxB1ZJSq040nwu-f5xMfbY2r7dBsMQvVgPr5FidNBtindz2yzS-pbNQRzZJ9oSzM04QorDLDBGkqPwsNBY-6kCUgH1u5QVSgrPQ_b3RixDTNc6_A_ONtNRRTzt3xC1CTf_3YjZyF2LCSWnmLr&xkcb=SoD967M3sVnfBoyEjh0AbzkdCdPP&fccid=c71b680e92ae5dd6&vjs=3\n",
      "Description: Job Information\n",
      "Date Opened\n",
      "05/13/2025\n",
      "Job Type\n",
      "Full time\n",
      "Industry\n",
      "Technology\n",
      "Work Experience\n",
      "1-3 years\n",
      "City\n",
      "Pittsburgh\n",
      "State/Province\n",
      "Pennsylvania\n",
      "Country\n",
      "United States\n",
      "Zip/Postal Code\n",
      "15205\n",
      "About Us...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Job 5:\n",
      "Title: Principal Machine Learning Engineer- Perception\n",
      "Company: Motional\n",
      "Location: Remote in Pittsburgh, PA\n",
      "Salary: $199,000 - $266,500\n",
      "URL: https://www.indeed.com/rc/clk?jk=5902615c254aaeeb&bb=10-r0rBpzhMBnWYIxB1ZJZrHbpxeGl6mniaxnGcqctyIm6TV2uaSRM0fQrBWBG-UmFhkLH-WeFnIKYSg1Id1DWBgHU-wKeujx_2HvbYrD2D1vjJrVTusVBH1JLEQkYFY0StkRfDExTEnUfvVLFalpVSG5x2prPJh&xkcb=SoBz67M3sVnfBoyEjh0HbzkdCdPP&fccid=86e1d3bf79028267&vjs=3\n",
      "Description: On our Perception team, you have the opportunity to work with world-class ML engineers and research scientists, whose mission is to make self-driving vehicles a reality and to create a positive social...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Job 6:\n",
      "Title: Software Engineer, Planner Vehicle Dynamics\n",
      "Company: Waymo\n",
      "Location: Pittsburgh, PA\n",
      "Salary: $204,000 - $259,000\n",
      "URL: https://www.indeed.com/rc/clk?jk=2f09a466d135ba37&bb=10-r0rBpzhMBnWYIxB1ZJXHK8egtY8FeJnSd0QNYGmWGxFlmWt8C0M5ULpl1x3wowjDYHbmVubLMmE1BblSE7qbroEvydx_QrEMVGWEKRZnk4dSFLhDRfEcb9EtklDjgv6IQBNyyOfrhs4HjAnfG3l1eghwmkKg4&xkcb=SoBJ67M3sVnfBoyEjh0BbzkdCdPP&fccid=73ceef0a2153d2b8&vjs=3\n",
      "Description: Waymo is an autonomous driving technology company with the mission to be the world's most trusted driver. Since its start as the Google Self-Driving Car Project in 2009, Waymo has focused on building ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Job 7:\n",
      "Title: Staff Scientist, Data Sciences\n",
      "Company: Thermo Fisher Scientific\n",
      "Location: Pittsburgh, PA 15205\n",
      "Salary: \n",
      "URL: https://www.indeed.com/rc/clk?jk=31fd282616fe12f1&bb=10-r0rBpzhMBnWYIxB1ZJXWM1EMJgz78muibyPtqgcP90GCro5_H07E8zQh7D550IebLtH4KIXyeYz9qmKXXapOJOVpXsBZx3VdOJB7sO3z3l8vl8UMijV-dduaCz2n7AZqkWmTR-MTsY6TaySUwBVnLHYZswF2O&xkcb=SoDH67M3sVnfBoyEjh0GbzkdCdPP&fccid=126e3afd205caa95&vjs=3\n",
      "Description: Work Schedule\n",
      "Standard (Mon-Fri)\n",
      "Environmental Conditions\n",
      "Office\n",
      "Job Description\n",
      "When you join us at Thermo Fisher Scientific, you’ll be part of an inquisitive team that shares your passion for explor...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Job 8:\n",
      "Title: Software Engineer - Machine Learning\n",
      "Company: Hike2\n",
      "Location: Remote in Pittsburgh, PA\n",
      "Salary: $100,000 - $170,000\n",
      "URL: https://www.indeed.com/rc/clk?jk=696f8bb513ef7f70&bb=10-r0rBpzhMBnWYIxB1ZJVtloTsGMnpbae09kIRVEoFMCTvwaRUNMto4fI9nXn0qoNVdfSCxSJ65AwC50IKQGwgpMg7-K7lwH7WXI8X5v4ZB0TQnpiLqFp7EUcLEAybdIN7RRBWieqdjjuS4CLqs-U7ZS3xX_DlH&xkcb=SoAH67M3sVnfBoyEjh0LbzkdCdPP&fccid=3aa37f402da13777&vjs=3\n",
      "Description: Who We Are\n",
      "HIKE2 is a leading provider of technology advisory and implementation services that specializes in empowering a distinct set of industries to define their future and accelerate their path f...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Job 9:\n",
      "Title: Data Scientist, New Graduate\n",
      "Company: Duolingo\n",
      "Location: Pittsburgh, PA\n",
      "Salary: $135,000 - $200,000\n",
      "URL: https://www.indeed.com/rc/clk?jk=252c1acf3cad34a8&bb=10-r0rBpzhMBnWYIxB1ZJVWCbAcl9E4nVOD7XUtlkIxEd6uCXDVFx899KNX0X_m53cVxcT5C1m9cCeVqb16_vQdcMujr7qghuY3CRneWXTLHTm0mGv163RDOPkCRr6cWrKIeW7_Xqy7Q4CX-Hw7cnmx2CDZ-OC-F&xkcb=SoCa67M3sVnfBoyEjh0IbzkdCdPP&fccid=1d7146bd38091a7a&vjs=3\n",
      "Description: Our mission at Duolingo is to develop the best education in the world and make it universally available. It's a big mission, and that's where you come in!\n",
      "At Duolingo, you'll join a team that cares ab...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Job 10:\n",
      "Title: Quantitative Trading Analyst\n",
      "Company: SESCO Enterprises\n",
      "Location: Pittsburgh, PA\n",
      "Salary: \n",
      "URL: https://www.indeed.com/rc/clk?jk=41b83a81a3216093&bb=10-r0rBpzhMBnWYIxB1ZJXRsNBEmKgdigMVYUzOltuvErzWkdG2ZU1writAF6NvOPwU1hP_SEmQz9upPmOA2hc5RfL5hsh4rgmB6q2KwlH-xEVPiJV7TknwZXU8qgcBn8xeL_ozI-nsa-dFzhWtRx_B_ppoN5Qvd&xkcb=SoBg67M3sVnfBoyEjh0DbzkdCdPP&fccid=d96d91f14d33cc13&vjs=3\n",
      "Description: 4350 Northern Pike Blvd\n",
      "Monroeville, PA 15146\n",
      "(724) 837-1991\n",
      "info@sescollc.com\n",
      "SESCO Enterprises, LLC is a proprietary commodities trading firm specializing in U.S. electricity markets. We leverage de...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Job 11:\n",
      "Title: Machine Learning Engineer\n",
      "Company: Adidev Technologies Inc\n",
      "Location: Pittsburgh, PA 15219 \n",
      "(Middle Hill area)\n",
      "Salary: \n",
      "URL: https://www.indeed.com/rc/clk?jk=33f09109d5e5c3a6&bb=10-r0rBpzhMBnWYIxB1ZJa5aIXkqeqZ1VONj72LJ3oBKGDwvb-AbndJW9q_3feTjeQxgbAd7JPlcRjhGpWHm59RN_by5_xqkhPePfrrnhk1izRbqmJMGqZDnZTbIWLeihwmx05i8hXwxLJF_FW1pVotrOsBEQLRD&xkcb=SoAu67M3sVnfBoyEjh0JbzkdCdPP&fccid=fb97ab53c1134fb9&vjs=3\n",
      "Description: Role: Machine Learning Engineer\n",
      "(This role is open to US Citizens, Green Card holders, GC-EAD only. We do not sponsor visas.)\n",
      "\n",
      "Summary:\n",
      "Adidev is looking for an adept Machine Learning Engineer to take...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Job 12:\n",
      "Title: Data Engineer\n",
      "Company: PNC Financial Services Group\n",
      "Location: Pittsburgh, PA\n",
      "Salary: \n",
      "URL: https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0AMofH_6zXbiqn6xehDj89HQNfpf30LHk40Y3Yl5cZTpm-EXukPQNet_K9MQV9Co4xuhwsJJ6oZ-irHoTk7Bl1QrbFEMbR1TZiX462ylRbKReiF6VBd_p5YtnPLQ9HNEf4h7f2S8_-V9wNnL_GUivjdJOg-bQYQYLW98XMBIdwuRJ2KKqYRvKqX-oH3k4QK6dyMIFT_OLJWE4_6mPPMCBMaDP2po55hIg9K-mWvRV5FH0AcXMATE2lv29awljM_mZ9T1fpyx3iNHMPAv6Lz-ROnckXtEeGJabJcTP7IolEJVYleD4eoxgqYdYcC71Przl048XHIShMuanZ2z4nRsWdi1HZe81exxIh3OVRurzac85C6TgOTX4jMKl6do4JCUpQIhAAvN8nKa3RyWgGsfZAOpaC2C1xftaL5aZvKocerafJd6cczuIrZQwD5KnzPDEccfOs35miZ-jJXcVstAbG7185TQkicV2iMQEVxhm_o5H6-7ggpq1qi8GjEpekz5lubIMBH-P3osrKkUqVb0_7NPXCoMuZC_z1Uhy9rsDu73W_j6j5nq446EKtgbdMiN-6v7EFx9skyfmlo-Zjrf24C8lBoZa7FGrxmoh2gwaAC3728sOEX-9pTf13HrOrHl8KcMjhhFlk5IVA0dtwgrisEnkmpDg8D8aHQxN41VMGXPugNUzT3fN0Qzu80B0KmSKHVXhr7bFoWi5fX0umdsFApshdE7dWSBVMXWdOUEThmpRtf0_Bx7DFxr17iPA26wX1j0_REmJsGdB8rnRi84kUmQER9UktShCKGy2_GQi4RTtFHrKMyuv285QKMjKWYeCXUkBAxdDocKBSqkk8dwKEhL6wCkvMqanC0RjXqaDx9dnFAcX65ZAe6Zf02mg11fLywBwuwvi3yiTEBmDAz9L7auBDpT2CaagANEfDPrkXX7saAG8_hwysOgnNO2ygydTPMfkVQw0waOtyALNo96EKW1Pz0LnBYznNn8JM_zcTtly_PLzLjYh4t4FKG8T9zzllKU0pobuQZ1dIDDt0TuafcGGLHFmu0ZnzJCH76fV5V36wM4Ld1RmNaCn8cs0yRvBOfg9ZP7ulgYgnPJan-3L6s41qZ95BeclrRvYcIaGPVjfZ7RNEGQ8B7AZRnRhclBvk_eqM9rV-1zjS3QxNgD3eK7wBZq2LsbJiwQoYLR2hSsYG_4DVAltsajzSzWDaZBalGEGGqPkUQ-5BVgrEk23_dDppbGirlrReFhpd1-X1lSA==&xkcb=SoBU6_M3sVnfBoyEjh0ObzkdCdPP&camk=tQsC0y0u1LpwjyZvQ6w3oQ==&p=5&fvj=0&vjs=3\n",
      "Description: Position Overview\n",
      "\n",
      "At PNC, our people are our greatest differentiator and competitive advantage in the markets we serve. We are all united in delivering the best experience for our customers. We work ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Job 13:\n",
      "Title: DATA / AI ENGINEER\n",
      "Company: ZAP Solutions\n",
      "Location: Pittsburgh, PA 15212 \n",
      "(North Shore area)\n",
      "Salary: \n",
      "URL: https://www.indeed.com/rc/clk?jk=2ceacb909ba01890&bb=10-r0rBpzhMBnWYIxB1ZJTWLmSrnl2Q3XkjZbGtlJb-h1PPgHXu-pFkuzXleWWYhRBFZl1wAqWK-I6HfFexKxqY_hOf7C0LXoDBVdCpUTzHHl9uDyyykwXGYmq4NRJXmmBxyXvw7nLZ-ZtKWqZzdqr5T1MKyYgdw&xkcb=SoCJ67M3sVnfBoyEjh0MbzkdCdPP&fccid=5c427e8200d57226&vjs=3\n",
      "Description: LOCATION: Pittsburgh, PA\n",
      "START DATE: TBD\n",
      "EMPLOYMENT TYPE: Full-time\n",
      "STARTING SALARY: Negotiable\n",
      "REQUIRED EDUCATION: Bachelors Degree or Equivalent Experience\n",
      "REQUIRED EXPERIENCE: Open\n",
      "RELATED CATEGORI...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Job 14:\n",
      "Title: MACHINE LEARNING ENGINEER\n",
      "Company: Qeexo, Co.\n",
      "Location: Pittsburgh, PA\n",
      "Salary: $105,000\n",
      "URL: https://www.indeed.com/rc/clk?jk=f529be1c093777fb&bb=10-r0rBpzhMBnWYIxB1ZJRnyrOwY4PosWcjiKMpl_CsgaRAzAKacgk5WjzxzNgNTck1xRUBnW6m-NOzxOgmESOKmgDieSzfiMMoya736qo70PrPpL3nsCWuGx-nNTahOilX1ORmL3DrRF0l3KHu1AqFwWmkK7Ibr&xkcb=SoCz67M3sVnfBoyEjh0KbzkdCdPP&fccid=68a181b72706f64f&vjs=3\n",
      "Description: MACHINE LEARNING ENGINEER JOB DESCRIPTION\n",
      "**This position is for our Pittsburgh, PA office - only apply if you are based there or willing to relocate**\n",
      "At TDK SensEI, we are transforming how industria...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Job 15:\n",
      "Title: Research Scientist\n",
      "Company: Oculus\n",
      "Location: Pittsburgh, PA\n",
      "Salary: $147,000 - $208,000\n",
      "URL: https://www.indeed.com/rc/clk?jk=74df39ab197ab579&bb=10-r0rBpzhMBnWYIxB1ZJZ38mKxy_SjQI90O3ve-ZNWM1kH6tZb61p7m5kVq8EsDC7ebjEb0AWv9ibhWv5PSwaJRHbvQjNWYLHTZV0q1Rs9z5lj9q6kobzjtcsmsiAVn1JwkQFRo2_ni_uqg0vlYD-ZbSx7Ipe7N&xkcb=SoBa67M3sVnfBoyEjh0FbzkdCdPP&fccid=ba07516c418dda52&vjs=3\n",
      "Description: In XRCIA, we aspire to achieve a vision of social presence in VR and AR where people are enabled to interact with each other across distances in a way that is indistinguishable from in-person interact...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Job 16:\n",
      "Title: \n",
      "Company: \n",
      "Location: \n",
      "Salary: \n",
      "URL: https://www.indeed.com/viewjob?jk=fedcba9876543210\n",
      "Description: None\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # User Input\n",
    "    print(\"Enter job title: \", end=\"\")\n",
    "    job_title = input()\n",
    "    print(job_title)\n",
    "    \n",
    "    print(\"Enter city: \", end=\"\")\n",
    "    city = input()\n",
    "    print(city)\n",
    "    \n",
    "    print(\"Enter state: \", end=\"\")\n",
    "    state = input()\n",
    "    print(state)\n",
    "    \n",
    "    print(\"Enter starting page (0 for first page, 1 for second page, etc.): \", end=\"\")\n",
    "    start_page_input = input()\n",
    "    start_page = int(start_page_input) if start_page_input.strip() else 0\n",
    "    print(f\"Starting from page {start_page + 1}\")\n",
    "    \n",
    "    print(\"Enter number of pages to scrape (default 1): \", end=\"\")\n",
    "    pages_input = input()\n",
    "    num_pages = int(pages_input) if pages_input.strip() else 1\n",
    "    print(f\"Will scrape {num_pages} pages\")\n",
    "    \n",
    "    # print(\"Enter number of parallel threads (default 3, max 5 recommended): \", end=\"\")\n",
    "    print(\"Enter number of parallel threads (default 3, 5 recommended, max 15 ): \", end=\"\")\n",
    "    threads_input = input()\n",
    "    max_workers = int(threads_input) if threads_input.strip() else 3\n",
    "    max_workers = min(max_workers, 15)\n",
    "    # max_workers = min(max_workers, 5)  # Cap at 5 to avoid detection\n",
    "    print(f\"Using {max_workers} parallel threads\")\n",
    "    \n",
    "    # Generate URL\n",
    "    url = get_url(job_title, city, state, start_page)\n",
    "    print(f\"Search URL: {url}\")\n",
    "    \n",
    "    # Setup Selenium WebDriver\n",
    "    driver = create_driver()\n",
    "    \n",
    "    records = []\n",
    "    \n",
    "    try:\n",
    "        for page_num in range(num_pages):\n",
    "            current_page = start_page + page_num\n",
    "            print(f\"\\nScraping page {current_page + 1}...\")\n",
    "            \n",
    "            # Navigate to URL\n",
    "            if page_num == 0:\n",
    "                driver.get(url)\n",
    "            else:\n",
    "                # Use saved next page URL or generate new one\n",
    "                if next_page_url:\n",
    "                    driver.get(next_page_url)\n",
    "                else:\n",
    "                    url = get_url(job_title, city, state, current_page)\n",
    "                    driver.get(url)\n",
    "            \n",
    "            # Wait for job listings to load\n",
    "            time.sleep(random.randint(3, 5))\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CLASS_NAME, \"job_seen_beacon\"))\n",
    "            )\n",
    "            \n",
    "            # Find all job posts\n",
    "            posts = driver.find_elements(By.CLASS_NAME, \"job_seen_beacon\")\n",
    "            print(f\"Found {len(posts)} jobs on page {page_num + 1}\")\n",
    "            \n",
    "            # First pass: collect basic info and URLs\n",
    "            job_basics = []\n",
    "            for i, post in enumerate(posts):\n",
    "                print(f\"Collecting basic info for job {i + 1}/{len(posts)}...\")\n",
    "                basic_info = get_job_basic_info(post)\n",
    "                if basic_info:\n",
    "                    job_basics.append(basic_info)\n",
    "            \n",
    "            print(f\"Collected {len(job_basics)} job listings from page {current_page + 1}\")\n",
    "            \n",
    "            # Save the next page URL before closing browser\n",
    "            next_page_url = None\n",
    "            if page_num < num_pages - 1:\n",
    "                try:\n",
    "                    next_button = driver.find_element(By.CSS_SELECTOR, \"a[data-testid='pagination-page-next']\")\n",
    "                    next_page_url = next_button.get_attribute(\"href\")\n",
    "                    print(f\"Next page URL saved: {next_page_url}\")\n",
    "                except NoSuchElementException:\n",
    "                    print(\"No next page button found\")\n",
    "            \n",
    "            # Close the listing page browser\n",
    "            driver.quit()\n",
    "            print(\"Closed listing page browser to avoid detection\")\n",
    "            \n",
    "            # Second pass: get job descriptions in parallel with multiple threads\n",
    "            print(f\"\\nFetching job descriptions using {max_workers} parallel threads...\")\n",
    "            start_time = time.time()\n",
    "            \n",
    "            with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "                # Submit all jobs to the thread pool\n",
    "                future_to_job = {\n",
    "                    executor.submit(process_job_with_description, job_data, i, len(job_basics)): job_data \n",
    "                    for i, job_data in enumerate(job_basics)\n",
    "                }\n",
    "                \n",
    "                # Collect results as they complete\n",
    "                for future in as_completed(future_to_job):\n",
    "                    try:\n",
    "                        record = future.result()\n",
    "                        records.append(record)\n",
    "                    except Exception as e:\n",
    "                        safe_print(f\"Error processing job: {e}\")\n",
    "            \n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(f\"\\nCompleted {len(job_basics)} jobs in {elapsed_time:.2f} seconds\")\n",
    "            print(f\"Average time per job: {elapsed_time/len(job_basics):.2f} seconds\")\n",
    "            \n",
    "            print(f\"Completed page {current_page + 1}. Total jobs collected: {len(records)}\")\n",
    "            \n",
    "            # Create new driver for next page if needed\n",
    "            if page_num < num_pages - 1 and next_page_url:\n",
    "                print(\"\\nCreating new browser for next page...\")\n",
    "                driver = create_driver()\n",
    "                time.sleep(random.randint(2, 4))\n",
    "            elif page_num < num_pages - 1:\n",
    "                print(\"No next page available, stopping pagination\")\n",
    "                break\n",
    "        \n",
    "        # Display results\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"SCRAPING COMPLETE - Collected {len(records)} jobs\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        for i, record in enumerate(records, 1):\n",
    "            print(f\"\\nJob {i}:\")\n",
    "            print(f\"Title: {record[0]}\")\n",
    "            print(f\"Company: {record[1]}\")\n",
    "            print(f\"Location: {record[2]}\")\n",
    "            print(f\"Salary: {record[3]}\")\n",
    "            print(f\"URL: {record[4]}\")\n",
    "            print(f\"Description: {record[5][:200]}...\" if len(record[5]) > 200 else f\"Description: {record[5]}\")\n",
    "            print(\"-\" * 80)\n",
    "    \n",
    "    finally:\n",
    "        # Make sure driver is closed\n",
    "        try:\n",
    "            driver.quit()\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return records\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    records = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "526c9bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data saved to indeed_jobs.csv\n"
     ]
    }
   ],
   "source": [
    "def save_to_csv(records, filename=\"jobs.csv\"):\n",
    "    \"\"\"Save job records to CSV\"\"\"\n",
    "    headers = [\"Title\", \"Company\", \"Location\", \"Salary\", \"URL\", \"Description\"]\n",
    "    with open(filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(headers)\n",
    "        writer.writerows(records)\n",
    "    print(f\"\\nData saved to {filename}\")\n",
    "\n",
    "save_to_csv(records, \"indeed_jobs.csv\")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
